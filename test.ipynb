{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiariZen Pipeline Test\n",
    "\n",
    "This notebook tests the DiariZen speaker diarization pipeline using the example audio provided in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/kappa/Documents/mouhssinework/DiariZen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kappa/Documents/mouhssinework/DiariZen/pyannote-audio/pyannote/audio/pipelines/speaker_verification.py:43: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091a2d0e0c9f4fea97119477f6d4e118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85d43b30a3241898e82b6eba820bd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration: {'model': {'path': 'diarizen.models.eend.model_wavlm_conformer.Model', 'args': {'wavlm_src': 'wavlm_base_s80_md', 'wavlm_layer_num': 13, 'wavlm_feat_dim': 768, 'attention_in': 256, 'ffn_hidden': 1024, 'num_head': 4, 'num_layer': 4, 'dropout': 0.1, 'chunk_size': 16, 'use_posi': False, 'output_activate_function': False, 'selected_channel': 0}}, 'inference': {'args': {'seg_duration': 16, 'segmentation_step': 0.1, 'batch_size': 32, 'apply_median_filtering': True}}, 'clustering': {'args': {'method': 'VBxClustering', 'min_speakers': 1, 'max_speakers': 20, 'ahc_criterion': 'distance', 'ahc_threshold': 0.6, 'Fa': 0.07, 'Fb': 0.8, 'lda_dim': 128, 'max_iters': 20}}}\n",
      "self.embedding: /home/kappa/.cache/huggingface/hub/models--pyannote--wespeaker-voxceleb-resnet34-LM/snapshots/837717ddb9ff5507820346191109dc79c958d614/pytorch_model.bin\n",
      "Processing ./example/EN2002a_30s.wav...\n",
      "Extracting segmentations.\n",
      "Extracting Embeddings.\n",
      "Clustering.\n",
      "\n",
      "Diarization turns:\n",
      "start=0.0s stop=0.8s speaker_1\n",
      "start=0.0s stop=2.6s speaker_0\n",
      "start=0.8s stop=13.6s speaker_2\n",
      "start=5.8s stop=6.4s speaker_0\n",
      "start=8.0s stop=13.6s speaker_0\n",
      "start=13.7s stop=18.4s speaker_1\n",
      "start=17.8s stop=18.2s speaker_2\n",
      "start=18.9s stop=19.5s speaker_0\n",
      "start=19.6s stop=20.0s speaker_1\n",
      "start=20.3s stop=22.3s speaker_2\n",
      "start=23.3s stop=23.5s speaker_1\n",
      "start=23.4s stop=30.4s speaker_0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Change to the DiariZen directory if we are not already there\n",
    "project_dir = os.path.join(os.getcwd(), 'DiariZen')\n",
    "if os.path.exists(project_dir):\n",
    "    os.chdir(project_dir)\n",
    "    print(f\"Changed directory to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "from diarizen.pipelines.inference import DiariZenPipeline\n",
    "\n",
    "# 1. Load pre-trained model\n",
    "print(\"Loading model...\")\n",
    "diar_pipeline = DiariZenPipeline.from_pretrained(\"BUT-FIT/diarizen-wavlm-base-s80-md\")\n",
    "\n",
    "# 2. Path to example audio\n",
    "audio_file = './example/EN2002a_30s.wav'\n",
    "\n",
    "# 3. Apply diarization pipeline\n",
    "print(f\"Processing {audio_file}...\")\n",
    "diar_results = diar_pipeline(audio_file)\n",
    "\n",
    "# 4. Print results\n",
    "print(\"\\nDiarization turns:\")\n",
    "for turn, _, speaker in diar_results.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diarizen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
